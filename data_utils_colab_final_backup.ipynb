{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bnoushin7/self-supervised-medical-imaging/blob/main/data_utils_colab_final_backup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -r requirements.txt\n",
        "!pip install monai==1.2.0\n",
        "#!pip install nibabel"
      ],
      "metadata": {
        "id": "SKTRr7wALEOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip covid_19.zip"
      ],
      "metadata": {
        "id": "X2ZBxwTvv8pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import monai\n",
        "import numpy as np\n",
        "from monai.data import CacheDataset, DataLoader, Dataset, DistributedSampler, SmartCacheDataset, load_decathlon_datalist\n",
        "from monai.transforms import (\n",
        "    AddChanneld,\n",
        "    AsChannelFirstd,\n",
        "    Compose,\n",
        "    CropForegroundd,\n",
        "    LoadImaged,\n",
        "    NormalizeIntensityd,\n",
        "    Orientationd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    RandSpatialCropSamplesd,\n",
        "    ScaleIntensityRanged,\n",
        "    Spacingd,\n",
        "    SpatialPadd,\n",
        "    ToTensord,\n",
        ")\n",
        "print(monai.__version__)"
      ],
      "metadata": {
        "id": "U1dA-gCKK3xZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3bc882-602a-46f2-855f-9b6fc736bf7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batchsize, channel, x, y ,z\n"
      ],
      "metadata": {
        "id": "fFGrRLNacmnp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lni3UX_-Jg5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "597080cd-31ee-478c-e567-875c566c86a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(a_min=-1000, a_max=1000, b_min=0.0, b_max=1.0, space_x=1.5, space_y=1.5, space_z=2.0, roi_x=96, roi_y=96, roi_z=96, batch_size=2, sw_batch_size=2, smartcache_dataset=False, cache_dataset=False, file='/root/.local/share/jupyter/runtime/kernel-a4b13a38-97be-45af-9434-7553971a94fe.json')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def get_args():\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Parse command line arguments.\")\n",
        "    parser.add_argument(\"--a_min\", default=-1000, type=float, help=\"a_min in ScaleIntensityRanged\")\n",
        "    parser.add_argument(\"--a_max\", default=1000, type=float, help=\"a_max in ScaleIntensityRanged\")\n",
        "    parser.add_argument(\"--b_min\", default=0.0, type=float, help=\"b_min in ScaleIntensityRanged\")\n",
        "    parser.add_argument(\"--b_max\", default=1.0, type=float, help=\"b_max in ScaleIntensityRanged\")\n",
        "    parser.add_argument(\"--space_x\", default=1.5, type=float, help=\"spacing in x direction\")\n",
        "    parser.add_argument(\"--space_y\", default=1.5, type=float, help=\"spacing in y direction\")\n",
        "    parser.add_argument(\"--space_z\", default=2.0, type=float, help=\"spacing in z direction\")\n",
        "    parser.add_argument(\"--roi_x\", default=96, type=int, help=\"roi size in x direction\")\n",
        "    parser.add_argument(\"--roi_y\", default=96, type=int, help=\"roi size in y direction\")\n",
        "    parser.add_argument(\"--roi_z\", default=96, type=int, help=\"roi size in z direction\")\n",
        "    parser.add_argument(\"--batch_size\", default=2, type=int, help=\"number of batch size\")\n",
        "    parser.add_argument(\"--sw_batch_size\", default=2, type=int, help=\"number of sliding window batch size\")\n",
        "    parser.add_argument(\"--smartcache_dataset\", action=\"store_true\", help=\"use monai smartcache Dataset\")\n",
        "    parser.add_argument(\"--cache_dataset\", action=\"store_true\", help=\"use monai cache Dataset\")\n",
        "    parser.add_argument('-f', '--file', help=argparse.SUPPRESS)\n",
        "\n",
        "\n",
        "    if 'ipykernel' in sys.argv[0]:\n",
        "        return parser.parse_args(args=[])\n",
        "    else:\n",
        "        return parser.parse_args()\n",
        "args = get_args()\n",
        "print(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskGenerator:\n",
        "    def __init__(self, input_size=256, mask_patch_size=64, model_patch_size=32, mask_ratio=0.2):\n",
        "        self.input_size = input_size\n",
        "        self.mask_patch_size = mask_patch_size\n",
        "        self.model_patch_size = model_patch_size\n",
        "        self.mask_ratio = mask_ratio\n",
        "\n",
        "        assert self.input_size % self.mask_patch_size == 0\n",
        "        assert self.mask_patch_size % self.model_patch_size == 0\n",
        "\n",
        "        self.rand_size = self.input_size // self.mask_patch_size\n",
        "        self.scale = self.mask_patch_size // self.model_patch_size\n",
        "\n",
        "        self.token_count = self.rand_size ** 3\n",
        "        self.mask_count = int(np.ceil(self.token_count * self.mask_ratio))\n",
        "\n",
        "    def __call__(self):\n",
        "        mask_idx = np.random.permutation(self.token_count)[:self.mask_count]\n",
        "        mask = np.zeros(self.token_count, dtype=int)\n",
        "        mask[mask_idx] = 1\n",
        "\n",
        "        mask = mask.reshape((self.rand_size, self.rand_size, self.rand_size))\n",
        "        mask = mask.repeat(self.scale, axis=0).repeat(self.scale, axis=1).repeat(self.scale,axis=2)\n",
        "\n",
        "        return mask"
      ],
      "metadata": {
        "id": "JR7wOt3uvrPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.transforms import Transform\n",
        "\n",
        "class Generate3DMask(Transform):\n",
        "    def __init__(self, mask_generator):\n",
        "        self.mask_generator = mask_generator\n",
        "\n",
        "    def __call__(self, data):\n",
        "        image = data['image']\n",
        "        mask = self.mask_generator()  # Generate 3D mask\n",
        "\n",
        "        # Ensure the mask has the same number of dimensions as the image\n",
        "        # Typically, image might have a channel dimension, so we add one to the mask\n",
        "        if len(mask.shape) < len(image.shape):\n",
        "            mask = np.expand_dims(mask, axis=0)\n",
        "\n",
        "        # Add the mask to the data dictionary\n",
        "        data['mask'] = mask\n",
        "        return data\n",
        "\n"
      ],
      "metadata": {
        "id": "J35o1bXwNOJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(args):\n",
        "\n",
        "    dir_path = \"/content/covid_19\"\n",
        "    jsonlist_covid = dir_path + \"/dataset_TCIAcovid19_0.json\"\n",
        "    datadir_covid = dir_path + \"/CT-Covid-19-August2020/\"\n",
        "    num_workers = 1\n",
        "\n",
        "\n",
        "    datalist_covid = load_decathlon_datalist(jsonlist_covid, False, \"training\", base_dir=datadir_covid)\n",
        "\n",
        "    vallist_covid = load_decathlon_datalist(jsonlist_covid, False, \"validation\", base_dir=datadir_covid)\n",
        "\n",
        "    # Initialize the MaskGenerator with the appropriate parameters\n",
        "    mask_generator = MaskGenerator()\n",
        "\n",
        "    train_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"image\"]),\n",
        "            AddChanneld(keys=[\"image\"]),\n",
        "            Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(\n",
        "                keys=[\"image\"], a_min=args.a_min, a_max=args.a_max, b_min=args.b_min, b_max=args.b_max, clip=True\n",
        "            ),\n",
        "            SpatialPadd(keys=\"image\", spatial_size=[args.roi_x, args.roi_y, args.roi_z]),\n",
        "            CropForegroundd(keys=[\"image\"], source_key=\"image\", k_divisible=[args.roi_x, args.roi_y, args.roi_z]),\n",
        "            RandSpatialCropSamplesd(\n",
        "                keys=[\"image\"],\n",
        "                roi_size=[args.roi_x, args.roi_y, args.roi_z],\n",
        "                num_samples=args.sw_batch_size,\n",
        "                random_center=True,\n",
        "                random_size=False,\n",
        "            ),\n",
        "            Generate3DMask(mask_generator),  # Add the custom mask generation transform\n",
        "            ToTensord(keys=[\"image\", \"mask\"]),  # Ensure \"mask\" is also transformed to a tensor\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    val_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"image\"]),\n",
        "            AddChanneld(keys=[\"image\"]),\n",
        "            Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(\n",
        "                keys=[\"image\"], a_min=args.a_min, a_max=args.a_max, b_min=args.b_min, b_max=args.b_max, clip=True\n",
        "            ),\n",
        "            SpatialPadd(keys=\"image\", spatial_size=[args.roi_x, args.roi_y, args.roi_z]),\n",
        "            CropForegroundd(keys=[\"image\"], source_key=\"image\", k_divisible=[args.roi_x, args.roi_y, args.roi_z]),\n",
        "            RandSpatialCropSamplesd(\n",
        "                keys=[\"image\"],\n",
        "                roi_size=[args.roi_x, args.roi_y, args.roi_z],\n",
        "                num_samples=args.sw_batch_size,\n",
        "                random_center=True,\n",
        "                random_size=False,\n",
        "            ),\n",
        "            ToTensord(keys=[\"image\"]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    if args.cache_dataset:\n",
        "        print(\"Using MONAI Cache Dataset\")\n",
        "        train_ds = CacheDataset(data=datalist_covid, transform=train_transforms, cache_rate=0.5, num_workers=num_workers)\n",
        "    elif args.smartcache_dataset:\n",
        "        print(\"Using MONAI SmartCache Dataset\")\n",
        "        train_ds = SmartCacheDataset(\n",
        "            data=datalist_covid,\n",
        "            transform=train_transforms,\n",
        "            replace_rate=1.0,\n",
        "            cache_num=2 * args.batch_size * args.sw_batch_size,\n",
        "        )\n",
        "    else:\n",
        "        print(\"Using generic dataset\")\n",
        "        train_ds = Dataset(data=datalist_covid, transform=train_transforms)\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds, batch_size=args.batch_size, num_workers=num_workers, drop_last=True\n",
        "    )\n",
        "\n",
        "    val_ds = Dataset(data=vallist_covid, transform=val_transforms)\n",
        "    val_loader = DataLoader(val_ds, batch_size=args.batch_size, num_workers=num_workers, shuffle=False, drop_last=True)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "\n",
        "\n",
        "def test_get_loader():\n",
        "\n",
        "    train_loader, val_loader = get_loader(args)\n",
        "\n",
        "    for batch in train_loader:\n",
        "      print(f\" batch['image'] size is:  {batch['image'].size()}\")\n",
        "      print(f\" batch['mask']  size is:  {batch['mask'].size()}\")\n",
        "\n",
        "test_get_loader()\n",
        "\n",
        "    # train_batch = next(iter(train_loader))\n",
        "    # print(\"Train batch keys:\", train_batch.keys())\n",
        "    # print(\"Train batch 'image' shape:\", train_batch[\"image\"].shape)\n",
        "\n",
        "\n",
        "    #val_batch = next(iter(val_loader))\n",
        "    # print(\"Validation batch keys:\", val_batch.keys())\n",
        "    # print(\"Validation batch 'image' shape:\", val_batch[\"image\"].shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMdCZ7HQM_hp",
        "outputId": "c3adb7e0-d34b-46a3-d0d5-0ab56f149285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using generic dataset\n",
            " batch['image'] size is:  torch.Size([4, 1, 96, 96, 96])\n",
            " batch['mask']  size is:  torch.Size([4, 1, 8, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.Size([1, 512, 512, 64])\n",
        "\n",
        "AddChanneld\n",
        "torch.Size([1, 1, 512, 512, 64])\n",
        "\n",
        "\n",
        "Orientationd\n",
        "torch.Size([1, 1, 512, 512, 64])\n",
        "\n",
        "\n",
        "ScaleIntensityRanged\n",
        "torch.Size([1, 1, 512, 512, 64])\n",
        "\n",
        "\n",
        "\n",
        "SpatialPadd\n",
        "torch.Size([1, 1, 512, 512, 96])\n",
        "\n",
        "\n",
        "CropForegroundd\n",
        "torch.Size([1, 1, 512, 512, 96])\n",
        "\n",
        "\n",
        "RandSpatialCropSamplesd\n",
        "torch.Size([2, 1, 96, 96, 96])\n"
      ],
      "metadata": {
        "id": "312-m2JCZBgF"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}